{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19ae0ff4",
   "metadata": {},
   "source": [
    "# Day 4: Real Dataset, DataLoader, and Training Loop (MNIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692c1732",
   "metadata": {},
   "source": [
    "<b>Main goal today:</b> Learn how to work with real-world datasets using PyTorch’s `Dataset` and `DataLoader`, and build a working digit classifier using the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b681ee6",
   "metadata": {},
   "source": [
    "| Concept                 | What it does                                         |\n",
    "| ----------------------- | ---------------------------------------------------- |\n",
    "| `torchvision.datasets`  | Load real datasets like MNIST, CIFAR10               |\n",
    "| `transforms.ToTensor()` | Converts images into tensors                         |\n",
    "| `DataLoader`            | Automatically batches, shuffles, and loads data      |\n",
    "| Training loop           | Trains on batches, tracks loss, evaluates            |\n",
    "| Model saving            | Save and load your trained models using `torch.save` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a2bf67",
   "metadata": {},
   "source": [
    "#### Step-by-Step: Digit Classification using MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed7e6c5",
   "metadata": {},
   "source": [
    "##### 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6338ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a7d33b",
   "metadata": {},
   "source": [
    "##### 2. Load the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6d827cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# Transform: convert PIL image to tensor (0–255 → 0–1)\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# Load training and test sets\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=True, transform=transform, download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=False, transform=transform, download=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf74f0be",
   "metadata": {},
   "source": [
    "#### Explanation:\n",
    "\n",
    "* <b>MNIST:</b> 70,000 grayscale digit images (0–9), 28×28 pixels\n",
    "\n",
    "* `transform`=transforms.ToTensor():\n",
    "\n",
    "* Converts image to a 1×28×28 tensor\n",
    "\n",
    "* Normalizes pixels from 0–255 to 0–1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d7a8e7",
   "metadata": {},
   "source": [
    "#### 3. Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0506b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
    "test_loader=DataLoader(test_dataset,batch_size=64,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f6092f",
   "metadata": {},
   "source": [
    "#### Explanation:\n",
    "\n",
    "* `batch_size=64`: gives 64 images in each training step\n",
    "\n",
    "* `shuffle=True`: shuffles the training data for better learning\n",
    "\n",
    "* You’ll loop over these loaders during training/testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d5d957",
   "metadata": {},
   "source": [
    "#### 4. Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bad0c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net=nn.Sequential(\n",
    "            nn.Flatten(),  # 1×28×28 → 784\n",
    "            nn.Linear(784,128),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(128,10)   # 10 output classes (0–9)\n",
    "        )\n",
    "    def forward(self,X):\n",
    "        return self.net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7767c75",
   "metadata": {},
   "source": [
    "#### Explanation:\n",
    "\n",
    "* `nn.Flatten():` reshapes 2D image into a flat vector: 28×28 = 784\n",
    "\n",
    "* `nn.Linear(784, 128):` first hidden layer\n",
    "\n",
    "* `nn.ReLU():` adds non-linearity\n",
    "\n",
    "* `nn.Linear(128, 10):` output layer for 10 digit classes\n",
    "\n",
    "* We wrap everything in `nn.Sequential` for clean and short code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60d29f4",
   "metadata": {},
   "source": [
    "#### 5. Initialize Model, Loss, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd77e8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SimpleNN()\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e39a75",
   "metadata": {},
   "source": [
    "##### Explanation:\n",
    "\n",
    "* CrossEntropyLoss is the standard loss for multi-class classification problems.\n",
    "\n",
    "* Adam is an optimizer like SGD, but faster and smarter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebd80ba",
   "metadata": {},
   "source": [
    "#### 6. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bec266e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 11.4954\n",
      "Epoch: 2, Loss: 9.3756\n",
      "Epoch: 3, Loss: 7.6379\n",
      "Epoch: 4, Loss: 5.8120\n",
      "Epoch: 5, Loss: 6.6658\n",
      "Epoch: 6, Loss: 6.6738\n",
      "Epoch: 7, Loss: 3.9045\n",
      "Epoch: 8, Loss: 5.4970\n",
      "Epoch: 9, Loss: 3.3137\n",
      "Epoch: 10, Loss: 5.1973\n",
      "Epoch: 11, Loss: 3.5577\n",
      "Epoch: 12, Loss: 1.6224\n",
      "Epoch: 13, Loss: 1.0239\n",
      "Epoch: 14, Loss: 0.4887\n",
      "Epoch: 15, Loss: 9.2714\n"
     ]
    }
   ],
   "source": [
    "epochs=15\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss=0\n",
    "    for images,labels in train_loader:\n",
    "        preds=model(images) #Forward prop\n",
    "        loss=loss_fn(preds,labels) #Calculate Loss\n",
    "        \n",
    "        optimizer.zero_grad() #Clear old gradients\n",
    "        loss.backward() # BackProp\n",
    "        optimizer.step() #Update weights\n",
    "        \n",
    "        total_loss+=loss.item()\n",
    "    \n",
    "    print(f\"Epoch: {epoch+1}, Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eacf246",
   "metadata": {},
   "source": [
    "#### Explanation:\n",
    "\n",
    "* `images:` batch of input images (shape: [64, 1, 28, 28])\n",
    "\n",
    "* `labels:` ground truth digits for each image (0 to 9)\n",
    "\n",
    "* `model(images):` returns logits (not probabilities) — shape [64, 10]\n",
    "\n",
    "* `loss.backward():` calculates gradients\n",
    "\n",
    "* `optimizer.step():` applies gradient updates\n",
    "\n",
    "* `zero_grad():` clears previous gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86758fa",
   "metadata": {},
   "source": [
    "##### 7. Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb159649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.00%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # Turn off gradient tracking for speed\n",
    "    for images, labels in test_loader:\n",
    "        preds = model(images)\n",
    "        predicted_labels = preds.argmax(dim=1)\n",
    "        correct += (predicted_labels == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5c1ec5",
   "metadata": {},
   "source": [
    "#### Explanation:\n",
    "\n",
    "* `preds.argmax(dim=1):` gives the class with highest score for each image\n",
    "\n",
    "* `== labels:` compares prediction with truth\n",
    "\n",
    "* `sum().item():` counts number of correct predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19e1e3d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
